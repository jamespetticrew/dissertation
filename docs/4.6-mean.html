<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="4.6 Mean function | dissertation.knit" />
<meta property="og:type" content="book" />

<meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">

<title>4.6 Mean function | dissertation.knit</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<!--bookdown:toc:end-->
<!--bookdown:toc:start-->
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="mean" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Mean function</h2>
<p>A GP models our belief about how far a true process might deviate from some given regression function. Any variation in the true process not captured by the regression function needs to be captured by the GP, which can often lead to less precision in emulator predictions. The following example gives an illustration of this.</p>
<p>Assume the simulator <span class="math inline">\(f(x)=x^2 - 5x\)</span> from Section <a href="3.10-hm-worked-example.html#hm-worked-example">3.10</a> and shown in Figure <a href="4.6-mean.html#fig:function-plot">4.2</a> is to be emulated using a GP and that the simulator can only be run at the five points shown. There is a region with no observed points, roughly between -9 and 0 on the x-axis. The emulator will have to interpolate in this region. There are no observations in the region above about 6 on the x-axis, the emulator will have to extrapolate in this region. There is a good amount of data around the point of inflection at <span class="math inline">\(x=2.5\)</span>. This is where the function varies the most.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:function-plot"></span>
<img src="dissertation_files/figure-html/function-plot-1.png" alt="A simple function to be emulated, with the five points used to build the emulator shown. There is a region with no training data from approximately x=-9 to x=0." width="80%" />
<p class="caption">
Figure 4.2: A simple function to be emulated, with the five points used to build the emulator shown. There is a region with no training data from approximately x=-9 to x=0.
</p>
</div>
<p>First a zero-mean GP emulator is built with a Matérn <span class="math inline">\(\frac{5}{2}\)</span> correlation function, without a ‘nugget’. The emulator is then used to predict, with 95% posterior predictive intervals, the value of the function at many points between x = -10 and 10. A second emulator is built using a simple first-order<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> mean function, which requires two more parameters to be estimated from the data. The results are shown in Figure <a href="4.6-mean.html#fig:predictors">4.3</a>. The predictive means of both emulators do a good job of reproducing the function and both emulators have larger predictive intervals further away from the data. However, the constant-mean emulator (right pane) shows greater precision in predictions, because some part of the function variation is encapsulated by the mean function.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:predictors"></span>
<img src="dissertation_files/figure-html/predictors-1.png" alt="Predictions using a zero-mean (left) and first-order mean (right) GP emulator trained on the five points shown for the function, with 95 percent predictive intervals shown. The emulators predict the training points exactly, and the width of the predictive intervals increases further from the data. The first-order mean emulator is able to interpolate and extrapolate with greater precision." width="80%" />
<p class="caption">
Figure 4.3: Predictions using a zero-mean (left) and first-order mean (right) GP emulator trained on the five points shown for the function, with 95 percent predictive intervals shown. The emulators predict the training points exactly, and the width of the predictive intervals increases further from the data. The first-order mean emulator is able to interpolate and extrapolate with greater precision.
</p>
</div>
<p>As the emulator tries to predict at points further away from the training data, the influence of the training data on the predictions drops off, and the emulator reverts to the mean function, as show in Figure <a href="4.6-mean.html#fig:predict-long">4.4</a>, where the zero-mean emulator on the left tends to zero with larger x, and the constant-mean emulator on the right tends to the mean function, albeit both with such wide posterior predictive intervals as to render the results quite useless.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:predict-long"></span>
<img src="dissertation_files/figure-html/predict-long-1.png" alt="Behaviour of the emulator as it predicts further from the training data. Both the zero-mean (left) and first-order mean (right) emulators tend to their respective mean functions as the distance from the observed data grows larger." width="80%" />
<p class="caption">
Figure 4.4: Behaviour of the emulator as it predicts further from the training data. Both the zero-mean (left) and first-order mean (right) emulators tend to their respective mean functions as the distance from the observed data grows larger.
</p>
</div>
<p>Theoretically, the mean function can be any linear (in the coefficients) function of the inputs <span class="math inline">\(\mathbf{x}\)</span>. Some sources <span class="citation">(<a href="#ref-gp_comparison" role="doc-biblioref">Erickson, Ankenman, and Sanchez 2018</a>)</span> favour a first order-only model, describing the estimation of coefficients for higher order polynomials as possibly extraneous. Prior knowledge of the process to be emulated can be useful in choosing a suitable mean function. In this dissertation, where, 28 input parameters were being varied, and knowledge of the relationship between them and the simulator output was limited, a mean function of the kind</p>
<p><span class="math display" id="eq:simple-mean-function">\[\begin{equation}
\tag{4.12}
\mu(\mathbf{x}) = \beta_0 + \sum_{i=1}^{28} \beta_i x_i
\end{equation}\]</span></p>
<p>was used, which meant that 29 parameters needed to be learned for the mean function. This was a practical choice - each emulator was trained using several hundred runs. Introducing second order terms may have required many more simulator runs to get good reliable estimates for the <span class="math inline">\(\mathbf{\beta}\)</span>, and the computational resource required for this was not available.
The choice of mean function, and other modelling choices, can also be a function of the software package used, and we discuss the choice of software implementation in the next section.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gp_comparison" class="csl-entry">
Erickson, Collin B, Bruce E Ankenman, and Susan M Sanchez. 2018. <span>“<span class="nocase">Comparison of Gaussian process modeling software</span>.”</span> <em>European Journal of Operational Research</em> 266 (1): 179–92.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>as in <span class="math inline">\(y=mx+c\)</span><a href="4.6-mean.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="4.5-covariance.html"><button class="btn btn-default">Previous</button></a>
<a href="4.7-model-complexity-and-the-predictive-distribution.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
