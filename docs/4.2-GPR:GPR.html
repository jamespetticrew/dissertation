<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="4.2 Gaussian process regression | dissertation.knit" />
<meta property="og:type" content="book" />

<meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">

<title>4.2 Gaussian process regression | dissertation.knit</title>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<!--bookdown:toc:end-->
<!--bookdown:toc:start-->
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="GPR:GPR" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Gaussian process regression</h2>
<p>In this section a single output of TALYS <span class="math inline">\(f_i\)</span> is reasoned about. No loss of generality is incurred by proceeding in this way, as all of the TALYS outputs were modelled independently, and the same reasoning applies to all of them equally, so the <span class="math inline">\(i\)</span> subscript is dropped for convenience.</p>
<p>A GPR model was used as an emulator for TALYS in order to predict, with associated uncertainty estimates, the simulator output <span class="math inline">\(f\)</span> at unobserved inputs <span class="math inline">\(\mathbf{x}^\dagger \in \mathcal{X}^\dagger\)</span>. If TALYS is run twice for some <span class="math inline">\(\mathbf{x}\)</span>, the two outputs <span class="math inline">\(f^{(1)}(\mathbf{x})\)</span> and <span class="math inline">\(f^{(2)}(\mathbf{x})\)</span> will be the same. Because TALYS is deterministic, <span class="math inline">\(f^{(1)}(\mathbf{x}) = f^{(2)}(\mathbf{x})~ \forall~ \mathbf{x}\)</span>. Consequently the uncertainty around <span class="math inline">\(f(\mathbf{x})\)</span> reduces to zero once it has been observed<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. However, for <span class="math inline">\(f(\mathbf{x}^\dagger)\)</span> where the output has not been observed (the simulator has not been run at <span class="math inline">\(\mathbf{x^\dagger}\)</span>), there is uncertainty about its output due to incomplete knowledge about the process. The models and their implementation are understood, but not well enough that it is known what they will predict for a given <span class="math inline">\(\mathbf{x}\)</span> without running the simulator. This uncertainty is often described as epistemic, and in the Bayesian framework, statistical models are used to describe our belief about unobserved quantities, and the uncertainty associated with that belief. Consequently, the outputs <span class="math inline">\(f(\mathcal{X^\dagger})\)</span> are modelled as random variables. It is assume that <span class="math inline">\(f\)</span> is the sum of a deterministic trend function, <span class="math inline">\(\mu(\mathbf{\cdot})\)</span> and a zero mean Gaussian process, <span class="math inline">\(Z(\mathbf{\cdot})\)</span> <span class="citation">(<a href="#ref-dicekriging" role="doc-biblioref">Roustant, Ginsbourger, and Deville 2012</a>)</span>:</p>
<p><span class="math display" id="eq:process">\[\begin{equation}
\tag{4.1}
f(\mathbf{x}) = \mu(\mathbf{x}) + Z(\mathbf{x}).
\end{equation}\]</span></p>
<p>A Gaussian process (GP) is an infinite collection of random variables, any finite number of which has a multivariate Gaussian distribution <span class="citation">(<a href="#ref-gp4ml" role="doc-biblioref">Williams and Rasmussen 2006</a>)</span>. In practice the interest lies with two subsets of all possible <span class="math inline">\(f(\mathbf{x})\)</span>, the observed simulator outputs <span class="math inline">\(f(\mathcal{X^*})\)</span>, and the outputs we wish to predict <span class="math inline">\(f(\mathcal{X^\dagger})\)</span>. Before any simulator outputs are observed, our belief about the joint distribution of the observed and unobserved outputs is modelled as</p>
<p><span class="math display" id="eq:joint-distro">\[\begin{equation}
\tag{4.2}
\begin{bmatrix} \mathbf{f(\mathcal{X}^*)} \\
\mathbf{f(\mathcal{X}^\dagger)}
\end{bmatrix}
\sim MVN\left( \begin{bmatrix} \mu(\mathcal{X^*})\\
\mu(\mathcal{X^\dagger}) \end{bmatrix},
\begin{bmatrix} \mathbf{\Sigma^*} &amp; \mathbf{\Sigma^{*\dagger}}\\
\mathbf{\Sigma^{\dagger*}} &amp; \mathbf{\Sigma^{ \dagger}} \end{bmatrix} \right)
\end{equation}\]</span></p>
<p>For some mean function <span class="math inline">\(\mu(\cdot)\)</span> and some covariance matrices <span class="math inline">\(\mathbf{\Sigma^*}, \mathbf{\Sigma^\dagger}\)</span>, which are functions of the <span class="math inline">\(\mathcal{X^*}\)</span> and <span class="math inline">\(\mathcal{X^\dagger}\)</span> respectively, and <span class="math inline">\(\mathbf{\Sigma^{*\dagger}} = (\mathbf{\Sigma^{ \dagger *}})^{-1}\)</span>, which are functions of both <span class="math inline">\(\mathcal{X^*}\)</span> and <span class="math inline">\(\mathcal{X^\dagger}\)</span>.</p>
<p>The function <span class="math inline">\(Z(\cdot)\)</span> is constrained to have specific properties in order to qualify as a GP, as the <span class="math inline">\(\Sigma\)</span> must have the similar fundamental properties as the covariance matrix of a multivariate normal distribution (Section <a href="4.5-covariance.html#covariance">4.5</a>). The function <span class="math inline">\(\mu(\cdot)\)</span> can be any normal linear regression function (Section <a href="4.6-mean.html#mean">4.6</a>).</p>
<p>Both <span class="math inline">\(\mu(\cdot)\)</span> and <span class="math inline">\(Z(\cdot)\)</span> are functions with parameters that must be learn about from the <span class="math inline">\((\mathcal{X^*}, f(\mathcal{X^*}))\)</span>. Parameter estimation methods vary between software implementations (Section <a href="4.8-gp-software.html#gp-software">4.8</a>). After learning the parameters, the distribution in Equation <a href="4.2-GPR:GPR.html#eq:joint-distro">(4.2)</a> is fully characterised for a given <span class="math inline">\(\mathcal{X^\dagger}\)</span>, and the outputs at these unknown points are emulated as the joint conditional distribution <span class="math inline">\(\mathbf{f}(\mathcal{X^\dagger})|\mathbf{f}(\mathcal{X^*})\)</span>.</p>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-dicekriging" class="csl-entry">
Roustant, Olivier, David Ginsbourger, and Yves Deville. 2012. <span>“<span class="nocase">DiceKriging, DiceOptim: Two R packages for the analysis of computer experiments by kriging-based metamodeling and optimization</span>.”</span> <em>Journal of Statistical Software</em> 51: 1–55.
</div>
<div id="ref-gp4ml" class="csl-entry">
Williams, Christopher KI, and Carl Edward Rasmussen. 2006. <em>Gaussian Processes for Machine Learning</em>. Vol. 2. 3. MIT press Cambridge, MA.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>provided that, as is the case with TALYS, the simulator is deterministic and consequently there is no uncertainty due to random behaviour, often called aleatoric uncertainty, associated with the process <span class="math inline">\(f\)</span>.<a href="4.2-GPR:GPR.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="4.1-introduction-2.html"><button class="btn btn-default">Previous</button></a>
<a href="4.3-model-selection.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
